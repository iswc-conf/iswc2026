const dagshtul = [
    {
        title: "Trust, Autonomy and Accountability in PKG-Based Agentic AI (TAPAI)",
        organizers: "John Domingue, Aidan Hogan, Luis-Daniel Ibanez, Oshani Seneviratne and Maria-Esther Vidal",
        description: "This workshop will address how personal knowledge graphs (PKGS) can help to engender trust, autonomy and accountability in the context of agentic artificial intelligence. The question of how AI agents could leverage personal data to provide higher levels of automation and personalization for users has not been well-explored. While foundational models can be trained on public corpora of text, the recent emergence of computer-using agents, personal agents, etc., raise questions about how the user’s personal data can be used, and concerns about how they could be abused, in such a setting. Can AI agents be trusted with personal and potentially highly-sensitive user information? How can users maintain autonomy over their personal data in such a setting? How can AI agents and providers be held accountable when personal data are abused? In this session, we will address research questions regarding the use of PKGs to provide users with enhanced control and safety guarantees regarding how AI agents access and use their personal data.",
        website: "https://tapai-iswc25.github.io",
        social_medias: [
            {
                social_media: "#TAPAI"
            }
        ]
    },
    {
        title: "Explainable AI using Ontologies and Knowledge Graphs",
        organizers: "Raghava Mutharaju and Manas Gaur",
        description: "AI systems are now ubiquitous. They are used in a variety of applications and domains such as healthcare, finance, security, travel, and e-commerce. Ensuring transparency and explainability is vital, not only for user trust but also for legal compliance. In the proposed workshop, we will discuss the role of ontologies and knowledge graphs in particular, but knowledge representation techniques in more general terms, for Explainable AI (XAI). While traditional explainability techniques rely on statistical cues, ontologies and knowledge graphs enable semantic grounding, facilitating richer and more accurate justifications. The need for such methods is underscored by regulatory frameworks like the EU AI Act and GDPR, which mandate the provision of meaningful explanations, particularly in high-risk and automated decision-making contexts. The discussion in the workshop will be organized around key themes such as the foundations of symbolic explainability, technical integration with black-box models, user-centered explanation design, evaluation methods, and cross-domain applications. We will have breakout sessions to discuss these themes. The outcome of the discussions can drive future research and is also helpful for researchers new to the field.",
        website: ""
    },
    {
        title: "Are Ontologies Still Relevant in the Era of LLMs?",
        organizers: "Raghava Mutharaju, Cogan Shimizu, and Valentina Tamma",
        description: "Ontologies are one of the key mechanisms for capturing domain knowledge in the form of important concepts and the relationships between them. It requires time, effort, and expertise to build the ontologies. They have been proven to be effective for applications involving data integration, question answering, recommendations, and explanation generation. However, Large Language Models (LLMs) trained on massive amounts of data are another source of knowledge. They are able to find interesting statistical patterns, memorize, and answer questions. On the other hand, they struggle with consistency and are prone to hallucinations. Given these trade-offs between ontologies and LLMs, in this workshop, we would like to explore three key questions -- a) applications/tasks that need grounded and high-quality curated knowledge in the form of ontologies (and LLMs just do not work in these cases), b) applications/tasks that were traditionally making use of ontologies but can now be handled very well by LLMs, and c) applications/tasks that need a combination of ontologies and LLMs. Discussion around these topics can drive future research and would also be very helpful for researchers new to the field.",
        website: ""
    },
    {
        title: "ReAGENT-SW: Realising Autonomous Generative agENTs for the Semantic Web",
        organizers: "Ora Lassila, Valentina Tamma, and Ilaria Tiddi",
        description: "The original vision of the Semantic Web, articulated in the seminal Scientific American article by Berners-Lee, Hendler, and Lassila, placed autonomous agents at the heart of the Web’s evolution: agents capable of discovering, reasoning over, and acting upon structured, linked data to assist users, automate tasks, collaborate across services, and facilitate knowledge-driven decision-making. These agents were conceived as proactive participants in a globally distributed, machine-readable ecosystem. However, two decades later and despite significant progress in ontologies, reasoning technologies, and the creation of a vast Linked Data cloud, autonomous agents that truly reason with and act upon structured knowledge remain elusive. The recent emergence of generative AI systems has revived interest in this vision; introducing new capabilities for communication, abstraction, and interaction, although often lacking semantic grounding, verifiability, or goal-driven autonomy. This Dagstuhl-style workshop aims to bring together researchers and practitioners to critically examine how recent developments can be harnessed to revisit and realise the agent-focussed vision of the Semantic Web. Through discussion that integrates relevant disciplines across the Semantic Web, artificial intelligence, multi-agent systems, and robotics, we will explore what opportunities generative AI introduces for autonomous agents capable of semantically grounded, context-aware, and interoperable decision-making, what challenges remain, and how we can build such agents - both in digital spaces and real-world environments.",
        website: "https://reagent-sw.github.io/",
    }
];

export {dagshtul};